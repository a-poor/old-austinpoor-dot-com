[
    {
        "title":"Type-Wrap",
        "description":[
            "A tiny Python package for function argument typechecking.",
            "The package only contains two decorator functions for checking types using function argument annotations.",
            "\"typewrap.checkInputs\" checks inputs and \"typewrap.checkInputs\" checks both inputs and outputs."
        ],
        "tools_used":[
            "python",
            "pypi",
            "type-checking",
            "decorators"
        ],
        "links":[
            {"text":"GitHub","link":"https://github.com/a-poor/typewrap"},
            {"text":"PyPi Package","link":"https://pypi.org/project/typewrap/"}
        ]
    },
    
    {
        "title":"D3 – Exploring Gender Representation",
        "description":[
            "Using D3 and ObservableHQ to visualize the unbalanced gender representation among artists in US museums.",
            "Read more about about the data and see the visual at the link below."
        ],
        "tools_used":[
            "observablehq",
            "d3",
            "javascript"
        ],
        "links":[
            {"text":"ObservableHQ Notebook","link":"https://observablehq.com/@a-poor/exploring-artist-representation-data"}
        ]
    },
    {
        "title":"D3 – Visualizing Common Distributions",
        "description":[
            "Using D3 and ObservableHQ to visualize some common probability distributions with various parameters."
        ],
        "tools_used":[
            "observablehq",
            "d3",
            "javascript"
        ],
        "links":[
            {"text":"ObservableHQ Notebook","link":"https://observablehq.com/@a-poor/visualizing-distributions"}
        ]
    },
    {
        "title":"D3 – Visualizing Bayesian Thinking",
        "description":[
            "Using D3 and ObservableHQ to create an interactive visualization of the \"Librarian vs Farmer\" question from Daniel Kahneman’s book Thinking, Fast and Slow, from a Bayesian perspective."
        ],
        "tools_used":[
            "observablehq",
            "d3",
            "javascript"
        ],
        "links":[
            {"text":"ObservableHQ Notebook","link":"https://observablehq.com/@a-poor/visualizing-bayesian-thinking"}
        ]
    },
    
    {
        "title":"ds-create",
        "description":[
            "My first Python package hosted on PyPi!",
            "A simple CLI program (inspired by create-react-app) for creating program templates.",
            "Stores a folder's contents as template that can be cloned again and again."
        ],
        "tools_used":[
            "python",
            "pypi",
            "cli"
        ],
        "links":[
            {"text":"GitHub","link":"https://github.com/a-poor/ds-create"},
            {"text":"PyPi Package","link":"https://pypi.org/project/ds-create/"}
        ]
    },
    {
        "title":"NYC COVID-19 Dashboard",
        "description":[
            "A dashboard for exploring data related to the COVID-19 pandemic in New York City, using data fom the NYC Health Department.",
            "Built with Plotly and Dash and hosted on Heroku."
        ],
        "tools_used":[
            "plotly",
            "dash",
            "heroku"
        ],
        "links":[
            {"text":"GitHub","link":"https://github.com/a-poor/ap-covid-dashboard"},
            {"text":"Live Site","link":"https://ap-covid-dashboard.herokuapp.com/"}
        ]
    },
    {
        "title":"Saving the Dinosaurs with Reinforcement Learning",
        "description":[
            "A project where I created a bot to play Chrome's No-Internet Dinosaur Game using both reinforcement learning and a heuristic approach.",
            "My bot was able to get a high score of over 16,000."
        ],
        "tools_used":[
            "selenium",
            "tensorflow",
            "reinforcement-learning",
            "deep-q-learning"
        ],
        "links":[
            {"text":"GitHub Repo","link":"https://github.com/a-poor/chrome-dino-solver"},
            {"text":"Presentation Video","link":"https://www.youtube.com/watch?v=vKNHtvma0bQ"}
        ]
    },
    {
        "title":"Austin Recommends Movies",
        "description":[
            "I combined multiple datasets to create a movie recommendation system that uses both collaborative filtering and content-based filtering to make recommendations.",
            "My content-based filtering used a variety of NLP techniques to find similar films based on film summaries.",
            "I also created a simple prototype of my recommendation website using Flask, Bokeh, PostgreSQL, and an AWS EC2 instance."
        ],
        "tools_used":[
            "postgresql",
            "aws-ec2",
            "recommender-systems",
            "nlp",
            "nmf",
            "scikit-learn",
            "flask",
            "bootstrap",
            "bokeh"
        ],
        "links":[
            {"text":"GitHub Repo","link":"https://github.com/a-poor/movie-recs"}
        ]
    },
    {
        "title":"Predicting Spotify Track Skips",
        "description":[
            "I built a model to predict Spotify users' skip behavior based on track data and past listening data.",
            "I also wrote up a Medium blog post about it that was published in Towards Data Science."
        ],
        "tools_used":[
            "postgresql",
            "aws-ec2",
            "classification",
            "gradient-boosted-tree"
        ],
        "links":[
            {"text":"GitHub Repo","link":"https://github.com/a-poor/spotify-skip-prediction"},
            {"text":"Blog Post","link":"https://towardsdatascience.com/predicting-spotify-track-skips-49cf4a48b2a5"}
        ]
    },
    {
        "title":"Wrongfully Accused – NYC Housing Court",
        "description":[
            "This project was the equivalent of a senior thesis that I worked on for the course Wrongfully Accused at Sarah Lawrence. I investigated litigation practices in NYC housing court. One of my main focuses was on the improper service of process for eviction notices.",
            "In the course of my investigation, I spoke with numerous sources (lawyers, judges, process servers, and advocates), submitted a FOIL requests to the City of New York, visited NYC housing court, and used data science tools to web-scrape and analyze housing court records.",
            "The final result of my project was a 4,000+ word article."
        ],
        "tools_used":[
            "requests",
            "beautiful-soup",
            "shoe-leather"
        ],
        "links":[
            {"text":"GitHub Repo","link":"https://github.com/a-poor/wa_process_server"},
            {"text":"Article","link":"https://sites.google.com/gm.slc.edu/apoor-gutterservice/home"}
        ]
    },
    {
        "title":"Bio-Inspired Artificial Intelligence – Political Text Classification",
        "description":[
            "I worked on this semester-long project for the course Bio-Inspired Artificial Intelligence at Sarah Lawrence.",
            "Using a neural network, I was able to classify the polical leaning of a news article based on its content."
        ],
        "tools_used":[
            "keras",
            "nlp",
            "web-scraping",
            "beautiful-soup",
            "lstm"
        ],
        "links":[
            {"text":"GitHub Repo","link":"https://github.com/a-poor/PoliticalTextClassification"}
        ]
    },
    {
        "title":"NYC Craigslist Apartment Rental Pricing",
        "description":[
            "I web-scraped Craigslist listings for NYC apartment rentals and used regression (linear, polynomial, ridge, and lasso) to make rent price predictions."
        ],
        "tools_used":[
            "web-scraping",
            "scikit-learn",
            "qgis",
            "linear-regression",
            "geo-pandas"
        ],
        "links":[
            {"text":"GitHub Repo","link":"https://github.com/a-poor/nyc-apt-rental-predictions"}
        ]
    }
]
